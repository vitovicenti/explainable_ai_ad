{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9821335,"sourceType":"datasetVersion","datasetId":6003271},{"sourceId":9845607,"sourceType":"datasetVersion","datasetId":6038599},{"sourceId":5111,"sourceType":"modelInstanceVersion","modelInstanceId":3899,"modelId":1902},{"sourceId":6074,"sourceType":"modelInstanceVersion","modelInstanceId":4694,"modelId":2823},{"sourceId":11384,"sourceType":"modelInstanceVersion","modelInstanceId":6216,"modelId":3301}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install textstat\n!pip install groq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:49:39.744003Z","iopub.execute_input":"2024-11-11T09:49:39.744487Z","iopub.status.idle":"2024-11-11T09:50:06.003962Z","shell.execute_reply.started":"2024-11-11T09:49:39.744444Z","shell.execute_reply":"2024-11-11T09:50:06.002338Z"}},"outputs":[{"name":"stdout","text":"Collecting textstat\n  Downloading textstat-0.7.4-py3-none-any.whl.metadata (14 kB)\nCollecting pyphen (from textstat)\n  Downloading pyphen-0.17.0-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from textstat) (70.0.0)\nDownloading textstat-0.7.4-py3-none-any.whl (105 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.1/105.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyphen-0.17.0-py3-none-any.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyphen, textstat\nSuccessfully installed pyphen-0.17.0 textstat-0.7.4\nCollecting groq\n  Downloading groq-0.11.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: anyio<5,>=3.5.0 in /opt/conda/lib/python3.10/site-packages (from groq) (4.4.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from groq) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from groq) (0.27.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from groq) (2.9.2)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from groq) (1.3.1)\nRequirement already satisfied: typing-extensions<5,>=4.7 in /opt/conda/lib/python3.10/site-packages (from groq) (4.12.2)\nRequirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (3.7)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.5.0->groq) (1.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (2024.8.30)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1,>=0.23.0->groq) (1.0.5)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.9.0->groq) (2.23.4)\nDownloading groq-0.11.0-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: groq\nSuccessfully installed groq-0.11.0\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from datetime import datetime\nimport math\nimport textstat\nimport spacy\n\ndef retrieve_json_info(json_data, top_five_regions):\n    model_used = json_data[0]['Models_used']\n    scan_type = json_data[0]['Data']['Scan_type']\n    metrics = json_data[0]['Metrics']\n    heatmaps_str = json_data[0]['Visual_heatmaps']\n    heatmaps = [json.loads(h) for h in heatmaps_str.split('\\n') if h]\n    json_input = \"\"\n\n    json_input += \" Models used:\"\n    json_input += f\" Classification: {model_used['Classification_model']} \\t\"\n    json_input += f\" Visual explainability: {model_used['Visual_explainability_model']} \\t\"\n\n    json_input += f\" Scan type: {scan_type} \\t\"\n    \n    json_input += \" Metrics:\\n\"\n    json_input += f\" ROC AUC: {metrics['ROC_AUC']}\"\n    json_input += f\" Accuracy: {metrics['accuracy']}\"\n    json_input += f\" Precision: {metrics['precision']}\"\n    json_input += f\" Recall: {metrics['recall']}\"\n    json_input += f\" F1 Score: {metrics['f1_score']} \\t\"\n    \n    if top_five_regions == True:\n        top_heatmaps = sorted(heatmaps, key=lambda x: x['%_Heatmap'], reverse=True)[:5]\n        for entry in top_heatmaps:\n            json_input += f\"{entry['Region']}: \"\n            json_input += f\"{entry['%_Heatmap']:.2f}%\"\n            json_input += f\", {entry['%_Region']:.2f}% -\\t \"\n    else:\n        for entry in heatmaps:\n            json_input += f\"{entry['Region']}: \"\n            json_input += f\"{entry['%_Heatmap']:.2f}%\"\n            json_input += f\", {entry['%_Region']:.2f}% -\\t \"\n    return json_input\n\ndef do_inference(prompt, model):\n    starting_time = datetime.now()\n    \n    model.config.pad_token_id = model.config.eos_token_id\n\n    inputs = tokenizer(prompt, return_tensors=\"pt\")\n    inputs.to(device)\n    output = model.generate(inputs.input_ids,\n                            attention_mask=inputs.attention_mask,\n                            max_length=2048)  \n    ending_time = datetime.now()\n    total_time = ending_time - starting_time\n    return tokenizer.decode(output[0]), total_time.total_seconds()\n\ndef textual_metrics(input, language):\n    \n    nlp = spacy.load(\"en_core_web_sm\")\n    doc = nlp(input.lower())\n    \n    tokens = [token.text for token in doc if not token.is_punct]\n    unique_tokens = set(tokens)\n\n    ttr = len(unique_tokens) / len(tokens) #type-token ration\n    #ms = (math.log(len(unique_tokens)) - math.log(len(tokens))) / (math.log(len(unique_tokens)**2)) # Maas' score\n    \n    if language == 'EN':                                                           \n        read = textstat.flesch_reading_ease(input)  # Flesch reading ease test, only for English\n        fog_index = textstat.gunning_fog(input)\n        dale_chall = textstat.dale_chall_readability_score(input)  \n        ari_score = textstat.automated_readability_index(input)\n        colemanliau = textstat.coleman_liau_index(input)\n    elif language == 'IT':\n        read = textstat.gulpease_index(input)\n        fog_index = 0\n        dale_chall = 0\n  \n    print(f'TTR: {ttr} \\n Readability:: {read}\\n FOG index: {fog_index}\\n Dale-Chall: {dale_chall}\\n ARI score: {ari_score} \\n Coleman-Liau: {colemanliau}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:54:32.479914Z","iopub.execute_input":"2024-11-11T09:54:32.480448Z","iopub.status.idle":"2024-11-11T09:54:38.543421Z","shell.execute_reply.started":"2024-11-11T09:54:32.480401Z","shell.execute_reply":"2024-11-11T09:54:38.542193Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import os\nimport json\nfrom groq import Groq\n\nos.environ['GROQ_API_KEY']=\"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\"\n\nwith open(\"/kaggle/input/json-reports-2/json_report_t1w_CN (202).json\", \"r\") as f:\n    json_cn = json.load(f)\n    \nwith open(\"/kaggle/input/json-reports-2/json_report_t1w_cMCI (156).json\", \"r\") as f:\n    json_cmci = json.load(f)\n\nwith open(\"/kaggle/input/json-reports-2/json_report_t1w_ncMCI (205).json\", \"r\") as f:\n    json_ncmci = json.load(f)\n\nwith open(\"//kaggle/input/json-reports-2/json_report_t1w_AD (60).json\", \"r\") as f:\n    json_ad = json.load(f)\n\n\njson_cn=retrieve_json_info(json_cn, top_five_regions=False)\njson_cmci=retrieve_json_info(json_cmci, top_five_regions=False)\njson_ncmci=retrieve_json_info(json_ncmci, top_five_regions=False)\njson_ad=retrieve_json_info(json_ad, top_five_regions=False)\n\nprompt1_en = f\"\"\"The provided data are derived from a brain MRI study {json_cmci}. Each row describes an area of the Julich-Brain Atlas, the percentages of the heatmap within each region and the second percentage indicating the impact on the region. Please generate a report in which you describe the functioning of each region, according to the Julich-Brain Atlas, noting the percentages of the heatmap within each region and the impact on the region. Provide explanations in a clear manner that can be easily understood by medical professionals. Discuss the potential reasons why the model might have focused on this region, given its known roles and functions in the brain. Please don't insert the name of the classification and the visual explainability models used. Explain the clinical implications of the model's focus on this region, such as how it might encourage further investigation into early signs of the mild cognitive condition of the Alzheimer's Disease.\"\"\"\n\nprompt2_en_cn_ncmci = f\"\"\"The provided data are derived from a brain MRI study {json_cn}, {json_ncmci}. The first json data is about a patient classified by the model as cognitively normal (CN), the second is a non-converter-MCI case. (ncMCI). \\\nEach section of the visual heatmaps describes an area of the Julich-Brain Atlas, the percentages of the heatmap within each region and the second percentage indicating the impact on the region. \\\nCompare the regions highlighted in the two patients, analyze the regions in common and regions that don’t and the level of focus of the model, explaining the known roles of brain regions in Alzheimer's disease and in converter MCI case. Explain the clinical implications of the model's focus on this region, such as how it might encourage further investigation into early signs of the mild cognitive condition of the Alzheimer's Disease. Please don't insert into the report the name of classification and visual explainability models used.\nPlease remember that the heatmap does not describe areas that are affected by the disease, but the areas that were the most relevant for the model to reach its classification.\"\"\"\n\nprompt2_en_cn_ad = f\"\"\"The provided data are derived from a brain MRI study {json_cn}, {json_ad}. The first json data is about a patient classified by the model as cognitively normal (CN), the second is an Alzheimer’s disease case. (AD). \\\nEach section of the visual heatmaps describes an area of the Julich-Brain Atlas, the percentages of the heatmap within each region and the second percentage indicating the impact on the region. \\\nCompare the regions highlighted in the two patients, analyze the regions in common and regions that don’t and the level of focus of the model, explaining the known roles of brain regions in Alzheimer's disease. Explain the clinical implications of the model's focus on this region, such as how it might encourage further investigation into early signs of the mild cognitive condition of the Alzheimer's Disease. Please don't insert into the report the name of classification and visual explainability models used.\nPlease remember that the heatmap does not describe areas that are affected by the disease, but the areas that were the most relevant for the model to reach its classification.\"\"\"\n\nprompt2_en_cmci_ncmci = f\"\"\"The provided data are derived from a brain MRI study {json_cmci}, {json_ncmci}. The first json data is about a patient classified by the model as converter MCI (cMCI), the second is non-converter case (ncMCI). \\\nEach section of the visual heatmaps describes an area of the Julich-Brain Atlas, the percentages of the heatmap within each region and the second percentage indicating the impact on the region. \\\nCompare the regions highlighted in the two patients, analyze the regions in common and regions that don’t and the level of focus of the model, explaining the known roles of brain regions in Alzheimer's disease. Explain the clinical implications of the model's focus on this region, such as how it might encourage further investigation into early signs of the mild cognitive condition of the Alzheimer's Disease. Please don't insert into the report the name of classification and visual explainability models used.\nPlease remember that the heatmap does not describe areas that are affected by the disease, but the areas that were the most relevant for the model to reach its classification.\"\"\"\n\n\n\nmodels = [\"llama3-8b-8192\",\n         \"mixtral-8x7b-32768\",\n         \"gemma2-9b-it\",\n         \"gemma-7b-it\",\n         \"llama-3.1-70b-versatile\"]\n\nclient = Groq(api_key=os.environ.get(\"GROQ_API_KEY\"))\n\nchat_completion = client.chat.completions.create(\n    messages=[\n        {\n            \"role\": \"user\",\n            \"content\": prompt2_en_cmci_ncmci\n        }\n    ],\n    model=models[2])\n\noutput_text = chat_completion.choices[0].message.content\nprint(output_text)\n\ntextual_metrics(output_text, 'EN')","metadata":{"execution":{"iopub.status.busy":"2024-11-11T09:58:08.437862Z","iopub.execute_input":"2024-11-11T09:58:08.438782Z","iopub.status.idle":"2024-11-11T09:58:10.539496Z","shell.execute_reply.started":"2024-11-11T09:58:08.438736Z","shell.execute_reply":"2024-11-11T09:58:10.538300Z"},"trusted":true},"outputs":[{"name":"stdout","text":"This data provides interesting insights into how a model used to differentiate between converter MCI (cMCI) and non-converter MCI (ncMCI) patients focuses on specific brain regions.  \n\n**Commonalities and Differences:**\n\nWhile the exact regions highlighted vary across the three patients, we notice some common trends.  For instance, areas like the  **medial geniculate body**, **Broca's area**, and **the  anterior intra-parietal sulcus** are frequently emphasized.  These regions play crucial roles in auditory processing, language, and attention, all of which are known to be affected in Alzheimer's disease (AD) progression.  \n\nOn the other hand, variations exist in the specific regions highlighted and their level of importance. This suggests that the model might be capturing subtle differences in the **pattern of brain involvement** between cMCI and ncMCI patients, even at an early stage. \n\n**Clinical Implications:**\n\nThe model's focus on these specific brain regions has significant clinical implications:\n\n* **Early Detection:** The model's ability to differentiate between cMCI and ncMCI based on these subtle regional differences suggests its potential for earlier detection of AD. By identifying patients at higher risk of progressing to AD, interventions could be implemented earlier, potentially slowing disease progression.\n\n* **Targeted Interventions:** Understanding which brain regions are most implicated in the transition from MCI to AD could lead to the development of more targeted interventions. Therapies could be designed to specifically address the dysfunction in these areas, potentially improving cognitive outcomes. \n\n* **Biomarker Discovery:** The model's findings could guide research into identifying new biomarkers for AD. \n\n By pinpointing the regions with increased importance, researchers can investigate the underlying biological changes occurring in these areas, potentially leading to new diagnostic tools and therapeutic targets.\n\n\n**Important Considerations:**\n\nIt's crucial to remember that these findings are based on a model's interpretation of brain data. Further validation and research are needed to confirm the clinical significance of these observations. This model should not be used for standalone diagnosis but as a tool to guide clinical decision-making and research. \n\nTTR: 0.5246376811594203 \n Readability:: 24.48\n FOG index: 15.79\n Dale-Chall: 10.04\n ARI score: 18.4 \n Coleman-Liau: 17.0\n","output_type":"stream"}],"execution_count":4}]}