{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:20:41.985213Z",
     "iopub.status.busy": "2024-10-28T13:20:41.984469Z",
     "iopub.status.idle": "2024-10-28T13:20:56.451523Z",
     "shell.execute_reply": "2024-10-28T13:20:56.450421Z",
     "shell.execute_reply.started": "2024-10-28T13:20:41.985173Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting monai\n",
      "  Downloading monai-1.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.24 in /opt/conda/lib/python3.10/site-packages (from monai) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.9 in /opt/conda/lib/python3.10/site-packages (from monai) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.9->monai) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.9->monai) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.9->monai) (1.3.0)\n",
      "Downloading monai-1.4.0-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: monai\n",
      "Successfully installed monai-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install monai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:40:53.262418Z",
     "iopub.status.busy": "2024-10-28T13:40:53.261989Z",
     "iopub.status.idle": "2024-10-28T13:40:53.338853Z",
     "shell.execute_reply": "2024-10-28T13:40:53.338089Z",
     "shell.execute_reply.started": "2024-10-28T13:40:53.262376Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import monai\n",
    "from monai.data import DataLoader, decollate_batch, CacheDataset\n",
    "from monai.metrics import ROCAUCMetric\n",
    "from monai.data import DataLoader, ImageDataset\n",
    "from monai.transforms import Activations, AsDiscrete, Compose\n",
    "import os, random, time, calendar, datetime, warnings\n",
    "from sys import platform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "import warnings\n",
    "from monai.networks.nets import DenseNet121\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "import monai\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score, f1_score,  roc_auc_score, classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def set_determinism(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed) \n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "set_determinism(seed=10)\n",
    "\n",
    "\"\"\"\n",
    "Create a dictionary {'image': link, 'label': label} specifying the channels (T1w, T2w)\n",
    "\"\"\"\n",
    "\n",
    "def obtain_channel_data(df, channel, classes):\n",
    "\n",
    "    label_map = {\n",
    "        'AD': 0,\n",
    "        'CN': 1,\n",
    "        'cMCI': 2,\n",
    "        'ncMCI': 3\n",
    "    }\n",
    "\n",
    "    df['labels'] = df['label'].map(label_map)\n",
    "    df_train = df[df['set'] == 'train']\n",
    "    df_val = df[df['set'] == 'val']\n",
    "    df_test = df[df['set'] == 'test']\n",
    "    \n",
    "    column = f'{channel}_path'\n",
    "    \n",
    "    df_train = df_train[[column, 'labels']].copy()\n",
    "    df_train.rename(columns={column: 'image'}, inplace=True)\n",
    "    df_train.rename(columns={'labels': 'label'}, inplace=True)\n",
    "    df_train['image'] = df_train['image'].str.replace(r'\\\\', '/', regex=False)\n",
    "\n",
    "    df_val = df_val[[column, 'labels']].copy()\n",
    "    df_val.rename(columns={column: 'image'}, inplace=True)\n",
    "    df_val.rename(columns={'labels': 'label'}, inplace=True)\n",
    "    df_val['image'] = df_val['image'].str.replace(r'\\\\', '/', regex=False)\n",
    "\n",
    "    df_test = df_test[[column, 'labels']].copy()\n",
    "    df_test.rename(columns={column: 'image'}, inplace=True)\n",
    "    df_test.rename(columns={'labels': 'label'}, inplace=True)\n",
    "    df_test['image'] = df_test['image'].str.replace(r'\\\\', '/', regex=False)\n",
    "\n",
    "    \n",
    "    df_train['label'] = df_train['label'].apply(lambda x: torch.nn.functional.one_hot(torch.as_tensor(x), num_classes=classes).float())\n",
    "    df_val['label'] = df_val['label'].apply(lambda x: torch.nn.functional.one_hot(torch.as_tensor(x), num_classes=classes).float())\n",
    "    df_test['label'] = df_test['label'].apply(lambda x: torch.nn.functional.one_hot(torch.as_tensor(x), num_classes=classes).float())\n",
    "    \n",
    "    df_train=df_train.reset_index()\n",
    "    df_val=df_val.reset_index()\n",
    "    df_test=df_test.reset_index()\n",
    "\n",
    "    return df_train, df_val, df_test\n",
    "                \n",
    "scan_type = 'T2w'\n",
    "task = 'ternary1' # [all, binary1, binary2, ternary1, ternary2]\n",
    "\n",
    "classes=4\n",
    "data=pd.read_csv('/kaggle/input/oasis-final/metadata_updated.csv')  \n",
    "\n",
    "if task =='binary1':\n",
    "    data=data[(data['label'] == 'CN') | (data['label'] == 'AD')]\n",
    "    classes=2\n",
    "elif task =='ternary1':\n",
    "    data=data[(data['label'] == 'CN') | (data['label'] == 'AD') | (data['label'] == 'cMCI')]\n",
    "    classes=3\n",
    "elif task =='ternary2':\n",
    "    data=data[(data['label'] == 'CN') | (data['label'] == 'cMCI') | (data['label'] == 'ncMCI')]\n",
    "    classes=3    \n",
    "elif task =='binary2':\n",
    "    data=data[(data['label'] == 'cMCI') | (data['label'] == 'ncMCI')]\n",
    "    classes=2   \n",
    "elif task == 'all':\n",
    "    classes=4\n",
    "\n",
    "train_set, val_set, test_set = obtain_channel_data(data, scan_type, classes)\n",
    "pin_memory = torch.cuda.is_available()\n",
    "\n",
    "train_ds = ImageDataset(image_files=train_set['image'], labels=train_set['label'])\n",
    "train_loader = DataLoader(train_ds, batch_size=8, shuffle=True, num_workers=4, pin_memory=pin_memory)\n",
    "\n",
    "val_ds = ImageDataset(image_files=val_set['image'], labels=val_set['label'])\n",
    "val_loader = DataLoader(val_ds, batch_size=8, shuffle=True, num_workers=4, pin_memory=pin_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:21:50.437449Z",
     "iopub.status.busy": "2024-10-28T13:21:50.436831Z",
     "iopub.status.idle": "2024-10-28T13:21:50.817577Z",
     "shell.execute_reply": "2024-10-28T13:21:50.816568Z",
     "shell.execute_reply.started": "2024-10-28T13:21:50.437404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss_function, optimizer, val_interval, max_epochs, early_stopping, device):\n",
    "    saved_path = '/kaggle/working/'\n",
    "    reports_path = '/kaggle/working/'\n",
    "    reports_file = '/kaggle/working/results.csv'\n",
    "    logs_path = '/kaggle/working/'\n",
    "    results=[]\n",
    "    best_metric, best_metric_epoch = -1, -1\n",
    "    epoch_loss_values = [[], []]\n",
    "    metric_values = []\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    print('Device currently active: ', device)\n",
    "    for epoch in range(max_epochs):\n",
    "        print(\"-\" * 10)\n",
    "        print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
    "        model.train()\n",
    "        epoch_loss_train = 0\n",
    "        epoch_loss_eval = 0\n",
    "        step = 0\n",
    "        step_eval = 0\n",
    "\n",
    "        for batch_data in train_loader:\n",
    "            step += 1\n",
    "            inputs, labels = batch_data[0].to(device), batch_data[1].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss_train += loss.item()\n",
    "            epoch_len = len(train_ds) // train_loader.batch_size\n",
    "            if step % 50 == 0:\n",
    "                print(f\"{step}/{epoch_len}, train_loss: {loss.item():.4f}\")\n",
    "            writer.add_scalar(\"train_loss\", loss.item(), epoch_len * epoch + step)\n",
    "\n",
    "        epoch_loss_train /= step\n",
    "        epoch_loss_values[0].append(epoch_loss_train)\n",
    "        print(f\"epoch {epoch + 1} average loss: {epoch_loss_train:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if (epoch + 1) % val_interval == 0:\n",
    "            model.eval()\n",
    "            num_correct = 0.0\n",
    "            metric_count = 0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "            all_probs=[]\n",
    "            for val_data in val_loader:\n",
    "                step_eval += 1\n",
    "                val_images, val_labels = val_data[0].to(device), val_data[1].to(device)\n",
    "                with torch.no_grad():\n",
    "                    val_outputs = model(val_images)\n",
    "\n",
    "                    all_preds.append(val_outputs.argmax(dim=1).cpu().numpy())\n",
    "                    all_labels.append(val_labels.argmax(dim=1).cpu().numpy())  # true labels\n",
    "                    all_probs.append(F.softmax(val_outputs, dim=1).cpu().numpy())  # Store probabilities\n",
    "\n",
    "                    value = torch.eq(val_outputs.argmax(dim=1), val_labels.argmax(dim=1))\n",
    "                    metric_count += len(value)\n",
    "                    num_correct += value.sum().item()\n",
    "                    val_loss = loss_function(val_outputs, val_labels)\n",
    "                    epoch_loss_eval += val_loss.item()\n",
    "\n",
    "            epoch_loss_eval /= step_eval\n",
    "            epoch_loss_values[1].append(epoch_loss_eval)\n",
    "\n",
    "\n",
    "            all_preds = np.concatenate(all_preds)\n",
    "            all_labels = np.concatenate(all_labels)\n",
    "            all_probs = np.concatenate(all_probs)\n",
    "\n",
    "            accuracy = accuracy_score(all_labels, all_preds)\n",
    "            precision = precision_score(all_labels, all_preds, average='macro',zero_division=0)\n",
    "            recall = recall_score(all_labels, all_preds, average='macro',zero_division=0)\n",
    "            f1 = f1_score(all_labels, all_preds, average='macro',zero_division=0)\n",
    "\n",
    "            if classes==2:\n",
    "                auc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "            else:\n",
    "                auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "\n",
    "            if auc > best_metric:\n",
    "                best_metric = auc\n",
    "                best_metric_epoch = epoch + 1\n",
    "                torch.save(model.state_dict(), \"best_metric_model_classification3d_array.pth\")\n",
    "                print(\"saved new best metric model\")\n",
    "\n",
    "            print(f\"Current epoch: {epoch+1} current auc: {auc:.4f}\")\n",
    "            print(f\"Best auc: {best_metric:.4f} at epoch {best_metric_epoch}\")\n",
    "            print(f\"Accuracy: {accuracy:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, F1-Score: {f1:.4f}, AUC: {auc:.4f}\")\n",
    "            writer.add_scalar(\"val_accuracy\", accuracy, epoch + 1)\n",
    "            writer.add_scalar(\"precision\", precision, epoch + 1)\n",
    "            writer.add_scalar(\"recall\", recall, epoch + 1)\n",
    "            writer.add_scalar(\"f1_score\", f1, epoch + 1)\n",
    "            writer.add_scalar(\"AUC\", auc, epoch + 1)\n",
    "\n",
    "        if epoch + 1 - best_metric_epoch == early_stopping:\n",
    "            print(f\"\\nEarly stopping triggered at epoch: {str(epoch + 1)}\\n\")\n",
    "            break\n",
    "\n",
    "    print(f\"Training completed, best_metric: {best_metric:.4f} at epoch: {best_metric_epoch}\")\n",
    "\n",
    "    results.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'AUC': auc,\n",
    "        'train_loss': epoch_loss_train,\n",
    "        'val_loss': epoch_loss_eval,\n",
    "        'channel': scan_type,\n",
    "        'multiclass': task\n",
    "    })\n",
    "\n",
    "    if os.path.isfile(reports_file):\n",
    "        existing_df = pd.read_csv(reports_file)\n",
    "        new_df = pd.DataFrame(results)\n",
    "        updated_df = pd.concat([existing_df, new_df], ignore_index=True)\n",
    "    else:\n",
    "        updated_df = pd.DataFrame(results)\n",
    "    updated_df.to_csv(reports_file, index=False)\n",
    "    writer.close()\n",
    "    return results, epoch_loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:21:56.396002Z",
     "iopub.status.busy": "2024-10-28T13:21:56.395616Z",
     "iopub.status.idle": "2024-10-28T13:31:24.547170Z",
     "shell.execute_reply": "2024-10-28T13:31:24.545979Z",
     "shell.execute_reply.started": "2024-10-28T13:21:56.395967Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=classes).to(device)\n",
    "\n",
    "cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "adam_optimizer = torch.optim.Adam(model.parameters(),lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "results=[]\n",
    "epoch_loss_values = [[], []]\n",
    "\n",
    "results, epoch_loss_val= train_model(model,\n",
    "                                    train_loader=train_loader,\n",
    "                                    val_loader=val_loader,\n",
    "                                    loss_function=cross_entropy_loss, \n",
    "                                    optimizer=adam_optimizer, \n",
    "                                    val_interval=1, \n",
    "                                    max_epochs=50, \n",
    "                                    early_stopping=10, \n",
    "                                    device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:35:11.827110Z",
     "iopub.status.busy": "2024-10-28T13:35:11.826572Z",
     "iopub.status.idle": "2024-10-28T13:35:12.190064Z",
     "shell.execute_reply": "2024-10-28T13:35:12.189020Z",
     "shell.execute_reply.started": "2024-10-28T13:35:11.827062Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Print a graph representing loss function of training and evaluation\n",
    "\n",
    "train_losses = epoch_loss_val[0]\n",
    "val_losses = epoch_loss_val[1]\n",
    "epochs = range(1, len(train_losses) + 1)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(epochs, train_losses, 'r', label='Train Loss') \n",
    "plt.plot(epochs, val_losses, 'b', label='Validation Loss') \n",
    "plt.xticks(range(1, len(epochs) + 1, 2))\n",
    "plt.title('Train and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-28T13:41:02.574223Z",
     "iopub.status.busy": "2024-10-28T13:41:02.573790Z",
     "iopub.status.idle": "2024-10-28T13:41:09.110081Z",
     "shell.execute_reply": "2024-10-28T13:41:09.109103Z",
     "shell.execute_reply.started": "2024-10-28T13:41:02.574184Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Evaluation phase\n",
    "\n",
    "model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=classes).to(device)\n",
    "model_path = '/kaggle/input/20/pytorch/default/1/20.pth'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "test_ds = ImageDataset(image_files=test_set['image'], labels=test_set['label'])\n",
    "test_loader = DataLoader(test_ds, batch_size=16, shuffle=True, num_workers=4, pin_memory=pin_memory)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "all_probs=[]\n",
    "with torch.no_grad():\n",
    "    for test_data in test_loader:\n",
    "        test_images, test_labels = test_data[0].to(device), test_data[1].to(device)\n",
    "        test_outputs = model(test_images)\n",
    "        preds = test_outputs.argmax(dim=1) \n",
    "        all_probs.append(F.softmax(test_outputs, dim=1).cpu().numpy())\n",
    "        all_preds.append(preds.cpu().numpy())\n",
    "        all_labels.append(test_labels.argmax(dim=1).cpu().numpy())  \n",
    "all_preds = np.concatenate(all_preds)\n",
    "all_labels = np.concatenate(all_labels)\n",
    "all_probs = np.concatenate(all_probs)  \n",
    "\n",
    "\n",
    "\n",
    "print(\"Test Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))\n",
    "if classes==2:\n",
    "    auc = roc_auc_score(all_labels, all_probs[:, 1])\n",
    "else:\n",
    "    auc = roc_auc_score(all_labels, all_probs, multi_class='ovr', average='macro')\n",
    "print('AUC:',auc)\n",
    "\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5899741,
     "sourceId": 9668002,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 145114,
     "modelInstanceId": 122006,
     "sourceId": 143968,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145116,
     "modelInstanceId": 122008,
     "sourceId": 143970,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145121,
     "modelInstanceId": 122013,
     "sourceId": 143975,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145129,
     "modelInstanceId": 122024,
     "sourceId": 143994,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145132,
     "modelInstanceId": 122027,
     "sourceId": 143997,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145143,
     "modelInstanceId": 122040,
     "sourceId": 144010,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145204,
     "modelInstanceId": 122104,
     "sourceId": 144080,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145214,
     "modelInstanceId": 122115,
     "sourceId": 144092,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 145230,
     "modelInstanceId": 122131,
     "sourceId": 144110,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 145341,
     "modelInstanceId": 122249,
     "sourceId": 144243,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 145373,
     "modelInstanceId": 122282,
     "sourceId": 144282,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 149604,
     "modelInstanceId": 126640,
     "sourceId": 149191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 149607,
     "modelInstanceId": 126643,
     "sourceId": 149194,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
