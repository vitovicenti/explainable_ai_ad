{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "import torch\n",
    "from monai import transforms\n",
    "from monai.data import Dataset, DataLoader\n",
    "from monai.config import print_config\n",
    "import nibabel as nib\n",
    "from IPython.display import clear_output\n",
    "from monai.data import MetaTensor\n",
    "from monai.utils import set_determinism\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from monai.transforms import Compose, RandAxisFlip, RandShiftIntensity, OneOf, EnsureChannelFirst, Orientation, Spacing,  RandRotate, RandFlip, ToTensor, SpatialPad, ScaleIntensity, CropForeground,Resize, NormalizeIntensity, RandScaleIntensity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersample data to the second max label\n",
    "# applied at the beginning of the algorithm\n",
    "def undersample_data(dataset, features, verbose):\n",
    "    labels = dataset['label'].value_counts()\n",
    "    second_max_label = labels.nlargest(2).iloc[-1]\n",
    "    rusampler = RandomUnderSampler(sampling_strategy={'CN':second_max_label}, random_state=12)\n",
    "\n",
    "    X = dataset[features]  \n",
    "    y = dataset['label']  \n",
    "    X_resampled, y_resampled = rusampler.fit_resample(X, y)\n",
    "\n",
    "    df_undersampled = pd.DataFrame(X_resampled, columns=features)\n",
    "    df_undersampled['label'] = y_resampled\n",
    "\n",
    "    if verbose==True:\n",
    "        print(\"Original label distribution:\")\n",
    "        print(dataset['label'].value_counts())\n",
    "\n",
    "        print(\"\\nResampled label distribution:\")\n",
    "        print(df_undersampled['label'].value_counts())\n",
    "    \n",
    "    df_undersampled.reset_index(drop=True, inplace=True)\n",
    "    return df_undersampled\n",
    "\n",
    "# udnersample applied in the end to balance final classes\n",
    "def undersample_final_dataset(dataset, features, verbose):\n",
    "    rusampler = RandomUnderSampler(sampling_strategy='all', random_state=12)\n",
    "    X = dataset[features]  \n",
    "    y = dataset['label']  \n",
    "    X_resampled, y_resampled = rusampler.fit_resample(X, y)\n",
    "    df_undersampled = pd.DataFrame(X_resampled, columns=features)\n",
    "    df_undersampled['label'] = y_resampled\n",
    "    if verbose==True:\n",
    "        print(\"Original label distribution:\")\n",
    "        print(dataset['label'].value_counts())\n",
    "        print(\"\\nResampled label distribution:\")\n",
    "        print(df_undersampled['label'].value_counts())\n",
    "    df_undersampled.reset_index(drop=True, inplace=True)\n",
    "    return df_undersampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "\n",
    "# Create a data dictionary with the scan_type considered (T1w, T2w) and the associated label\n",
    "# take the last scan if more than one scan exists for each scan_type \n",
    "# this function is used to get only one scan_type path. To obtain both the scan paths refer to get_both_scans()\n",
    "\n",
    "def get_scan_dictionary(dataset, scan_type, verbose):\n",
    "\n",
    "    days_regex = r\"d(\\d{4})\"\n",
    "    path_o3 = 'C:/Users/Vito/Desktop/Magistrale/dataset tesi/OASIS3/oasis_3/mri'\n",
    "    path_o4 = 'C:/Users/Vito/Desktop/Magistrale/dataset tesi/OASIS4/oasis_4/data'\n",
    "    t1w_path = '' \n",
    "    t1w_file = ''\n",
    "    folders_not_founded=[]\n",
    "    data_dict = []\n",
    "    path = ''\n",
    "    y=0\n",
    "\n",
    "    for i in range(0, len(dataset)):\n",
    "\n",
    "        # check if the patients belongs to OASIS3 or OASIS4\n",
    "        dataset_type = (re.match(r'OAS(\\d)', dataset['OASISID'][i])).group(1)\n",
    "        if dataset_type == '3':\n",
    "            path = path_o3\n",
    "        elif dataset_type == '4':\n",
    "            path = path_o4\n",
    "        \n",
    "        # folder of the scans\n",
    "        full_path = os.path.join(path, dataset['folder_scan'][i])\n",
    "\n",
    "        if os.path.exists(full_path):\n",
    "\n",
    "            day_match = re.search(days_regex, dataset['folder_scan'][i])\n",
    "            d = day_match.group(1) if day_match else None\n",
    "\n",
    "            if d:         \n",
    "                tw_files = [f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-2_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_echo-2_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_echo-2_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_echo-2_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_{scan_type}.nii.gz',\n",
    "                            f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_{scan_type}.nii.gz']\n",
    "\n",
    "                file_found = False\n",
    "                for tw_file in tw_files:\n",
    "                    tw_path = os.path.join(full_path, tw_file)\n",
    "                    if os.path.exists(tw_path):\n",
    "                        data_dict.append({'image': tw_path, \n",
    "                                          'label': dataset['label'][i], \n",
    "                                          'folder_scan': dataset['folder_scan'][i],\n",
    "                                          'ternary_label': dataset['ternary_label'],\n",
    "                                          'CDR': dataset['CDRTOT'][i]\n",
    "                                          })\n",
    "                        file_found = True\n",
    "                        break\n",
    "\n",
    "                # if file is not found, search if there are more than one iterations on scans\n",
    "                if file_found == False:\n",
    "                    files = os.listdir(full_path)\n",
    "                    runs = []\n",
    "\n",
    "                    for file in files:\n",
    "                        if not file.startswith('.'):\n",
    "                            regex_max_value = f'_run-(\\d+)_{scan_type}'\n",
    "                            yn = re.search(regex_max_value, file)\n",
    "                            if yn:\n",
    "                                runs.append(int(yn.group(1))) \n",
    "                    if runs:\n",
    "                        # choose the most recent run\n",
    "                        y=str(max(runs))\n",
    "                                        \n",
    "                    \n",
    "                    chosen_files = [f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_run-0{y}_{scan_type}.nii.gz', \n",
    "                                    f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_run-0{y}_{scan_type}.nii.gz',\n",
    "\n",
    "                                    f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-2_run-0{y}_{scan_type}.nii.gz',\n",
    "                                    f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-1_run-0{y}_{scan_type}.nii.gz',\n",
    "                                    \n",
    "                                    f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_run-0{y}_{scan_type}.nii.gz',\n",
    "                                    f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_run-0{y}_{scan_type}.nii.gz']\n",
    "\n",
    "                    final_paths = [os.path.join(full_path, file) for file in chosen_files[:6]]\n",
    "\n",
    "                    file_found = False\n",
    "                    for paths in final_paths:\n",
    "                        if os.path.exists(paths):\n",
    "                            data_dict.append({'image': paths, \n",
    "                                    'label': dataset['label'][i], \n",
    "                                    'folder_scan': dataset['folder_scan'][i],\n",
    "                                    'ternary_label': dataset['ternary_label'],\n",
    "                                    'CDR': dataset['CDRTOT'][i]})\n",
    "                            file_found=True\n",
    "                            break\n",
    "                        \n",
    "                    if not file_found:\n",
    "                        folders_not_founded.append(final_paths[0])\n",
    "        else:\n",
    "            print(\"Error: folder not found\")\n",
    "    if verbose == True:\n",
    "        print(f\"Scans ({scan_type}) not included in the data: {folders_not_founded}\") \n",
    "        print('\\nLenght of the input set of data:', len(dataset), '\\nScans founded:', len(data_dict))\n",
    "    return data_dict\n",
    "\n",
    "\n",
    "def get_both_scans(dataset, verbose, path):\n",
    "\n",
    "    days_regex = r\"d(\\d{4})\"\n",
    "    \n",
    "    t1w_path = '' \n",
    "    t1w_file = ''\n",
    "    folders_not_founded=[]\n",
    "    data_dict = []\n",
    "\n",
    "    y=0\n",
    "    types = ['T1w', 'T2w']\n",
    "\n",
    "    for i in range(0, len(dataset)):\n",
    "        # check if the patients belongs to OASIS3/OASIS4\n",
    "        dataset_type = (re.match(r'OAS(\\d)', dataset['OASISID'][i])).group(1)\n",
    "        # Folder of the scans\n",
    "        full_path = os.path.join(path, dataset['folder_scan'][i])\n",
    "        if os.path.exists(full_path):\n",
    "            day_match = re.search(days_regex, dataset['folder_scan'][i])\n",
    "            d = day_match.group(1) if day_match else None\n",
    "            if d:   \n",
    "                file_names = []\n",
    "                file_names.append(dataset['OASISID'][i])\n",
    "                file_names.append(dataset['folder_scan'][i])\n",
    "                file_names.append(dataset['ternary_label'][i])\n",
    "                file_names.append(dataset['label'][i])\n",
    "                file_names.append(dataset['folder_scan'][i])\n",
    "                file_names.append(dataset['CDRTOT'][i])\n",
    "\n",
    "                for scan_type in types:      \n",
    "                    t1w_files = [f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-2_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_echo-2_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_echo-1_{scan_type}.nii.gz',\n",
    "\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_echo-2_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_echo--1_{scan_type}.nii.gz',\n",
    "\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_echo-2_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_echo--1_{scan_type}.nii.gz',\n",
    "\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_{scan_type}.nii.gz',\n",
    "                                f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_{scan_type}.nii.gz']\n",
    "\n",
    "                    file_found = False\n",
    "                    for t1w_file in t1w_files:\n",
    "                        t1w_path = os.path.join(full_path, t1w_file)\n",
    "                        if os.path.exists(t1w_path):\n",
    "                            file_names.append(t1w_path)\n",
    "                            file_found = True\n",
    "                            break\n",
    "\n",
    "                    # if file is not found, search if there are more than one iterations on scans\n",
    "                    if file_found == False:\n",
    "                        files = os.listdir(full_path)\n",
    "                        runs = []\n",
    "\n",
    "                        for file in files:\n",
    "                            if not file.startswith('.'):\n",
    "                                regex_max_value = f'_run-(\\d+)_{scan_type}'\n",
    "                                yn = re.search(regex_max_value, file)\n",
    "                                if yn:\n",
    "                                    runs.append(int(yn.group(1))) \n",
    "                        if runs:\n",
    "                            # Choose the most recent run\n",
    "                            y=str(max(runs))\n",
    "                                          \n",
    "                        chosen_files = [f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_run-0{y}_{scan_type}.nii.gz', \n",
    "                                        f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_run-0{y}_{scan_type}.nii.gz',\n",
    "\n",
    "                                        f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-2_run-0{y}_{scan_type}.nii.gz',\n",
    "                                        f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_echo-1_run-0{y}_{scan_type}.nii.gz',\n",
    "                                        \n",
    "                                        f'sub-{dataset[\"OASISID\"][i]}_ses-d{d}_acq-TSE_run-0{y}_{scan_type}.nii.gz',\n",
    "                                        f'sub-{dataset[\"OASISID\"][i]}_sess-d{d}_acq-TSE_run-0{y}_{scan_type}.nii.gz']\n",
    "\n",
    "                        final_paths = [os.path.join(full_path, file) for file in chosen_files[:6]]\n",
    "\n",
    "                        file_found = False\n",
    "                        for paths in final_paths:\n",
    "                            if os.path.exists(paths):\n",
    "                                file_names.append(paths)\n",
    "                                file_found=True\n",
    "                                break \n",
    "                        if not file_found:\n",
    "                            folders_not_founded.append(final_paths[0])\n",
    "                        \n",
    "                data_dict.append({'OASISID': file_names[0], \n",
    "                                  'folder': file_names[1], \n",
    "                                  'ternary_label': file_names[2], \n",
    "                                  'label': file_names[3], \n",
    "                                  'folder_scan': file_names[4], \n",
    "                                  'CDRTOT':file_names[5], \n",
    "                                  'T1w': file_names[6], \n",
    "                                  'T2w': file_names[7]})\n",
    "        else:   \n",
    "            print(\"Error: folder not found\")\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of scans to discart (t1w_keys - t2w_keys): 8\n",
      "Number of scans to discart (t2w_keys - t1w_keys): 0\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/Vito/Desktop/Magistrale/dataset tesi/df_with_labels.csv')\n",
    "data['label'].value_counts()\n",
    "\n",
    "data_t1w = get_scan_dictionary(data, 'T1w', verbose=False)\n",
    "data_t2w = get_scan_dictionary(data, 'T2w', verbose=False)\n",
    "\n",
    "t1w_keys = set([entry['image'].split(\"\\\\\")[-2] for entry in data_t1w])\n",
    "t2w_keys = set([entry['image'].split(\"\\\\\")[-2] for entry in data_t2w])\n",
    "\n",
    "scan_to_discart1 = t1w_keys - t2w_keys\n",
    "scan_to_discart2 = t2w_keys - t1w_keys\n",
    "\n",
    "print(\"Number of scans to discart (t1w_keys - t2w_keys):\", len(scan_to_discart1))\n",
    "print(\"Number of scans to discart (t2w_keys - t1w_keys):\", len(scan_to_discart2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data['folder_scan'].isin(scan_to_discart1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CN       1901\n",
       "AD        323\n",
       "ncMCI     245\n",
       "cMCI      108\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Undersampling of the original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label distribution:\n",
      "CN       1901\n",
      "AD        323\n",
      "ncMCI     245\n",
      "cMCI      108\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Resampled label distribution:\n",
      "AD       323\n",
      "CN       323\n",
      "ncMCI    245\n",
      "cMCI     108\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "features = ['OASISID','OASIS_session_label', 'folder_scan','CDRTOT', 'dataset_type']\n",
    "undersampled_df = undersample_data(data, features, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duplicates(first_set, second_set):\n",
    "    test_in_train = first_set['OASISID'].isin(second_set['OASISID']).any()\n",
    "    train_in_test = second_set['OASISID'].isin(first_set['OASISID']).any()\n",
    "\n",
    "    if test_in_train or train_in_test:\n",
    "        duplicates = True\n",
    "    else:\n",
    "        duplicates = False\n",
    "    return duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the test set (15% of the original data), stratifying by subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set:\n",
      " ncMCI    66\n",
      "CN       61\n",
      "AD       56\n",
      "cMCI     55\n",
      "Name: label, dtype: int64\n",
      "\n",
      " Training set:\n",
      " AD       267\n",
      "CN       262\n",
      "ncMCI    179\n",
      "cMCI      53\n",
      "Name: label, dtype: int64\n",
      "\n",
      " Is the same patient in both sets?: False\n"
     ]
    }
   ],
   "source": [
    "train_eval_ratio = 0.85\n",
    "\n",
    "# how many samples for each label the test set must contain\n",
    "max_label = undersampled_df['label'].value_counts().max()\n",
    "test_labels_ratio = int(max_label * (1 - train_eval_ratio))  \n",
    "\n",
    "random.seed(12)\n",
    "subjects = undersampled_df['OASISID'].unique().tolist()\n",
    "random.shuffle(subjects)\n",
    "\n",
    "test_pat=[]\n",
    "\n",
    "for label in undersampled_df['label'].unique():     \n",
    "    class_samples = undersampled_df[undersampled_df['label'] == label]\n",
    "    unique_class_subjects = class_samples['OASISID'].unique()\n",
    "    selected_test_subjects = random.sample(list(unique_class_subjects), test_labels_ratio)\n",
    "    test_pat.extend(selected_test_subjects)\n",
    "\n",
    "train_subjects = undersampled_df['OASISID'].unique()\n",
    "train_subjects = train_subjects[~pd.Series(train_subjects).isin(test_pat)]\n",
    "\n",
    "X_test_set = undersampled_df[undersampled_df['OASISID'].isin(test_pat)]\n",
    "X_train = undersampled_df[undersampled_df['OASISID'].isin(train_subjects) & \n",
    "                          (~undersampled_df['OASISID'].isin(X_test_set['OASISID']))]\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test_set = X_test_set.reset_index(drop=True)\n",
    "\n",
    "print('Test set:\\n', X_test_set['label'].value_counts())\n",
    "print('\\n Training set:\\n', X_train['label'].value_counts())\n",
    "\n",
    "print('\\n Is the same patient in both sets?:', check_duplicates(X_train, X_test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3800</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3797 │   │   │   │   </span>)                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3798 │   │   │   </span>casted_key = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._maybe_cast_indexer(key)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3799 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3800 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3801 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3802 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3803 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\index.pyx</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">138</span> in                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\index.pyx'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\index.pyx</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">165</span> in                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.index.IndexEngine.get_loc</span>                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\index.pyx'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\hashtable_class_helper.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5745</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\hashtable_class_helper.pxi'</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\hashtable_class_helper.pxi</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">5753</span> in             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">pandas._libs.hashtable.PyObjectHashTable.get_item</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\hashtable_class_helper.pxi'</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'ternary_label'</span>\n",
       "\n",
       "<span style=\"font-style: italic\">The above exception was the direct cause of the following exception:</span>\n",
       "\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Vito\\AppData\\Local\\Temp\\ipykernel_3748\\3311930654.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\Vito\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3748\\\\3311930654.py'</span>                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">C:\\Users\\Vito\\AppData\\Local\\Temp\\ipykernel_3748\\698632810.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">100</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_scan_dictionary</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">[Errno 2] No such file or directory: </span>                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000; font-style: italic\">'C:\\\\Users\\\\Vito\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3748\\\\698632810.py'</span>                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">380</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__getitem__</span>                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3802 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_single_key:                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3803 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.nlevels &gt; <span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>:                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3804 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._getitem_multilevel(key)                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 3805 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>indexer = <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.columns.get_loc(key)                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3806 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> is_integer(indexer):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3807 │   │   │   │   </span>indexer = [indexer]                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3808 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">c:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #808000; text-decoration-color: #808000\">.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">3802</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">get_loc</span>                                                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3799 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">try</span>:                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3800 │   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._engine.get_loc(casted_key)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3801 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> err:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>3802 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">raise</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">KeyError</span>(key) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">from</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff; text-decoration: underline\">err</span>                                              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3803 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">except</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">TypeError</span>:                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3804 │   │   │   │   # If we have a listlike key, _check_indexing_error will raise</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">3805 │   │   │   │   #  InvalidIndexError. Otherwise we fall through and re-raise</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">KeyError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'ternary_label'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m.py\u001b[0m:\u001b[94m3800\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3797 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m)                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3798 \u001b[0m\u001b[2m│   │   │   \u001b[0mcasted_key = \u001b[96mself\u001b[0m._maybe_cast_indexer(key)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3799 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3800 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3801 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3802 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3803 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\index.pyx\u001b[0m:\u001b[94m138\u001b[0m in                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\index.pyx'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\index.pyx\u001b[0m:\u001b[94m165\u001b[0m in                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpandas._libs.index.IndexEngine.get_loc\u001b[0m                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\index.pyx'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\hashtable_class_helper.pxi\u001b[0m:\u001b[94m5745\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\hashtable_class_helper.pxi'\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\Desktop\\Codice\\DL\\Code\\pandas\\_libs\\hashtable_class_helper.pxi\u001b[0m:\u001b[94m5753\u001b[0m in             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'c:\\\\Users\\\\Vito\\\\Desktop\\\\Codice\\\\DL\\\\Code\\\\pandas\\\\_libs\\\\hashtable_class_helper.pxi'\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'ternary_label'\u001b[0m\n",
       "\n",
       "\u001b[3mThe above exception was the direct cause of the following exception:\u001b[0m\n",
       "\n",
       "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────────────── \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m ───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Vito\\AppData\\Local\\Temp\\ipykernel_3748\\3311930654.py\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\Vito\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3748\\\\3311930654.py'\u001b[0m                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mC:\\Users\\Vito\\AppData\\Local\\Temp\\ipykernel_3748\\698632810.py\u001b[0m:\u001b[94m100\u001b[0m in \u001b[92mget_scan_dictionary\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m[Errno 2] No such file or directory: \u001b[0m                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[3;31m'C:\\\\Users\\\\Vito\\\\AppData\\\\Local\\\\Temp\\\\ipykernel_3748\\\\698632810.py'\u001b[0m                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m:\u001b[94m380\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m5\u001b[0m in \u001b[92m__getitem__\u001b[0m                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3802 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m is_single_key:                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3803 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[96mself\u001b[0m.columns.nlevels > \u001b[94m1\u001b[0m:                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3804 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._getitem_multilevel(key)                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 3805 \u001b[2m│   │   │   \u001b[0mindexer = \u001b[96mself\u001b[0m.columns.get_loc(key)                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3806 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m is_integer(indexer):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3807 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mindexer = [indexer]                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 3808 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33mc:\\Users\\Vito\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[33m.py\u001b[0m:\u001b[94m3802\u001b[0m in \u001b[92mget_loc\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3799 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3800 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._engine.get_loc(casted_key)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3801 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mKeyError\u001b[0m \u001b[94mas\u001b[0m err:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m3802 \u001b[2m│   │   │   │   \u001b[0m\u001b[94mraise\u001b[0m \u001b[96mKeyError\u001b[0m(key) \u001b[94mfrom\u001b[0m \u001b[4;96merr\u001b[0m                                              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3803 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mTypeError\u001b[0m:                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3804 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# If we have a listlike key, _check_indexing_error will raise\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m3805 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mKeyError: \u001b[0m\u001b[32m'ternary_label'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train['set'] = 'train+val'\n",
    "X_test_set['set'] = 'test'\n",
    "\n",
    "# df updated in every phase, this will be the final CSV\n",
    "final_df = pd.concat([X_train, X_test_set])\n",
    "final_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "t1w_paths = get_scan_dictionary(final_df, 'T1w', verbose=False)\n",
    "t2w_paths = get_scan_dictionary(final_df, 'T2w', verbose=False)\n",
    "\n",
    "# Add the T1w and T2w scan paths to 'final_df'\n",
    "t1w_d = {d['folder_scan']: d['image'] for d in t1w_paths if 'folder_scan' in d}\n",
    "t2w_d = {d['folder_scan']: d['image'] for d in t2w_paths if 'folder_scan' in d}\n",
    "\n",
    "final_df['T1w'] = final_df['folder_scan'].map(t1w_d)\n",
    "final_df['T2w'] = final_df['folder_scan'].map(t2w_d)\n",
    "final_df['aug'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function used to decide the name of the folder for the oversampled images\n",
    "def get_aug_folder_name(string, output_dir):\n",
    "    match = re.search(r'(OAS([34])(\\d{4})_MR_d(\\d{4}))', string)\n",
    "    mr_name = match.group(0) if match else None\n",
    "    counter_folder=2\n",
    "    folder_name=f\"{mr_name}_{counter_folder}\"\n",
    "    path_name=os.path.join(output_dir, folder_name)\n",
    "\n",
    "    while os.path.exists(path_name):\n",
    "        counter_folder = counter_folder + 1\n",
    "        folder_name = f\"{mr_name}_{counter_folder}\"\n",
    "        path_name = os.path.join(output_dir, folder_name)\n",
    "    return path_name, counter_folder\n",
    "\n",
    "def get_aug_file_name(string, scan_type,i):\n",
    "    pattern = r'OAS([34])(\\d{4})_MR_d(\\d{4})'\n",
    "    match = re.search(pattern, string)\n",
    "    d_type, id, days = '', '', ''\n",
    "    if match:\n",
    "        d_type = match.group(1)  \n",
    "        id = match.group(2)  \n",
    "        days = match.group(3)  \n",
    "    file_name = f\"OAS{d_type}{id}_d{days}_{i}_{scan_type}.nii.gz\"\n",
    "    return file_name\n",
    "\n",
    "# Oversampling function with transformations\n",
    "\n",
    "def oversample_scans(\n",
    "        df,\n",
    "        transformation_function,\n",
    "        output_dir,\n",
    "        class_ratios):\n",
    "    \n",
    "    oversampled_data = []\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # dictionary to track how many times each patient has been used\n",
    "    patient_selection_count = {pid: 0 for pid in df['OASISID'].unique()}\n",
    "\n",
    "    # oversample each class\n",
    "    for class_label, desired_count in class_ratios.items():\n",
    "\n",
    "        # filter original scans for the current class\n",
    "        class_samples = df[df['label'] == class_label].to_dict(orient='records')\n",
    "        current_count = len(class_samples)\n",
    "\n",
    "        for sample in class_samples:\n",
    "\n",
    "            if current_count < desired_count:\n",
    "                print(f\"Current label: {class_label} {current_count}/{desired_count}\")\n",
    "\n",
    "                if patient_selection_count[sample['OASISID']] == 0:  # if the patient has not been selected yet\n",
    "                    set_determinism(seed=np.random.randint(0, 10000))\n",
    "\n",
    "                    T1w_img_data = nib.load(sample['T1w']).get_fdata()\n",
    "                    transformed_image1 = transformation_function(MetaTensor(T1w_img_data))\n",
    "                    oversampled_image_np1 = transformed_image1.numpy()\n",
    "                    \n",
    "                    T2w_img_data = nib.load(sample['T2w']).get_fdata()\n",
    "                    transformed_image2 = transformation_function(MetaTensor(T2w_img_data))\n",
    "                    oversampled_image_np2 = transformed_image2.numpy()\n",
    "\n",
    "                    folder_path, i = get_aug_folder_name(sample['T1w'], output_dir)\n",
    "                    t1w_file_name = get_aug_file_name(sample['T1w'], 'T1w', i)\n",
    "                    t2w_file_name = get_aug_file_name(sample['T1w'], 'T2w', i)\n",
    "                    \n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    t1w_os_path = os.path.join(folder_path, t1w_file_name)\n",
    "                    t2w_os_path = os.path.join(folder_path, t2w_file_name)\n",
    "\n",
    "                    nib.save(nib.Nifti1Image(oversampled_image_np1, np.eye(4)), t1w_os_path)\n",
    "                    nib.save(nib.Nifti1Image(oversampled_image_np2, np.eye(4)), t2w_os_path)\n",
    "\n",
    "                    oversampled_data.append({\n",
    "                        'OASISID': sample['OASISID'],\n",
    "                        'OASIS_session_label': f\"{sample['folder_scan']}_{i}\",\n",
    "                        'folder_scan': f\"{sample['folder_scan']}_{i}\",\n",
    "                        'CDRTOT': sample['CDRTOT'],\n",
    "                        'dataset_type': 'aug',\n",
    "                        'ternary_label': sample['ternary_label'],\n",
    "                        'label': sample['label'],    \n",
    "                        'set': 'train+val',                                 \n",
    "                        'T1w': t1w_os_path, \n",
    "                        'T2w': t2w_os_path,\n",
    "                        'aug': 1\n",
    "                    })\n",
    "\n",
    "                    patient_selection_count[sample['OASISID']] += 1\n",
    "                    current_count+=1\n",
    "                    clear_output(wait=False) \n",
    "                \n",
    "        # perform additional sampling to reach desired_count\n",
    "        while current_count < desired_count:\n",
    "            print(f\"Current label: {class_label} {current_count}/{desired_count}\")\n",
    "\n",
    "            # calculate probabilities based on the selection count of the patients\n",
    "            probabilities = [1 / (patient_selection_count[sample['OASISID']] + 1) for sample in class_samples]\n",
    "            total_prob = sum(probabilities)\n",
    "            probabilities = [prob / total_prob for prob in probabilities]\n",
    "\n",
    "            sample_index = np.random.choice(range(len(class_samples)), p=probabilities)\n",
    "            sample = class_samples[sample_index]\n",
    "        \n",
    "            T1w_img_data = nib.load(sample['T1w']).get_fdata()\n",
    "            transformed_image1 = transformation_function(MetaTensor(T1w_img_data))\n",
    "            oversampled_image_np1 = transformed_image1.numpy()\n",
    "            \n",
    "            T2w_img_data = nib.load(sample['T2w']).get_fdata()\n",
    "            transformed_image2 = transformation_function(MetaTensor(T2w_img_data))\n",
    "            oversampled_image_np2 = transformed_image2.numpy()\n",
    "\n",
    "            folder_path, i = get_aug_folder_name(sample['T1w'], output_dir)\n",
    "\n",
    "            t1w_file_name = get_aug_file_name(sample['T1w'], 'T1w', i)\n",
    "            t2w_file_name = get_aug_file_name(sample['T1w'], 'T2w', i)\n",
    "\n",
    "            os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "            t1w_os_path = os.path.join(folder_path, t1w_file_name)\n",
    "            t2w_os_path = os.path.join(folder_path, t2w_file_name)\n",
    "\n",
    "            nib.save(nib.Nifti1Image(oversampled_image_np1, np.eye(4)), t1w_os_path)\n",
    "            nib.save(nib.Nifti1Image(oversampled_image_np2, np.eye(4)), t2w_os_path)\n",
    "\n",
    "            oversampled_data.append({\n",
    "                'OASISID': sample['OASISID'],\n",
    "                'OASIS_session_label': f\"{sample['folder_scan']}_{i}\",\n",
    "                'folder_scan': f\"{sample['folder_scan']}_{i}\",\n",
    "                'CDRTOT': sample['CDRTOT'],\n",
    "                'dataset_type': 'aug',\n",
    "                'ternary_label': sample['ternary_label'],\n",
    "                'label': sample['label'],    \n",
    "                'set': 'train+val',                                 \n",
    "                'T1w': t1w_os_path, \n",
    "                'T2w': t2w_os_path,\n",
    "                'aug': 1\n",
    "            })\n",
    "            \n",
    "            patient_selection_count[sample['OASISID']] += 1\n",
    "            current_count += 1\n",
    "            clear_output(wait=False) \n",
    "\n",
    "    return oversampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(string, scan_type):\n",
    "    pattern = r'OAS([34])(\\d{4})_MR_d(\\d{4})'\n",
    "    match = re.search(pattern, string)\n",
    "    d_type, id, days = '', '', ''\n",
    "    if match:\n",
    "        d_type = match.group(1)  \n",
    "        id = match.group(2)  \n",
    "        days = match.group(3)  \n",
    "    file_name = f\"OAS{d_type}{id}_d{days}_{scan_type}.nii.gz\"\n",
    "    return file_name\n",
    "\n",
    "# Transformations for the 'not augmented' files\n",
    "def train_eval_scans_transformation(\n",
    "        df,\n",
    "        transformation_function,\n",
    "        output_dir,\n",
    "        set):\n",
    "    \n",
    "    train_data_dict=[]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    created_folders=0\n",
    "    total_folders=len(df)\n",
    "    folders_not_added=0\n",
    "\n",
    "    for index, sample in df.iterrows():\n",
    "        set_determinism(seed=np.random.randint(0, 10000))\n",
    "\n",
    "        T1w_img_data = nib.load(sample['T1w']).get_fdata()\n",
    "        transformed_image1 = transformation_function(MetaTensor(T1w_img_data))\n",
    "        oversampled_image_np1 = transformed_image1.numpy()\n",
    "        \n",
    "        T2w_img_data = nib.load(sample['T2w']).get_fdata()\n",
    "        transformed_image2 = transformation_function(MetaTensor(T2w_img_data))\n",
    "        oversampled_image_np2 = transformed_image2.numpy()\n",
    "\n",
    "        folder_path = os.path.join(output_dir, sample['folder_scan'])\n",
    "        try:\n",
    "            os.makedirs(folder_path)\n",
    "            print(f\"Directory '{folder_path}' created: {created_folders}/{total_folders}\")\n",
    "        except FileExistsError:\n",
    "            print(f\"Directory '{folder_path}' already exists.\")\n",
    "            folders_not_added=folders_not_added+1\n",
    "\n",
    "        t1w_file_name = get_file_name(sample['T1w'], 'T1w')\n",
    "        t2w_file_name = get_file_name(sample['T1w'], 'T2w')\n",
    "\n",
    "        t1w_os_path = os.path.join(folder_path, t1w_file_name)\n",
    "        t2w_os_path = os.path.join(folder_path, t2w_file_name)\n",
    "\n",
    "        nib.save(nib.Nifti1Image(oversampled_image_np1, np.eye(4)), t1w_os_path)\n",
    "        nib.save(nib.Nifti1Image(oversampled_image_np2, np.eye(4)), t2w_os_path)\n",
    "\n",
    "        train_data_dict.append({'OASISID': sample['OASISID'],\n",
    "                        'OASIS_session_label': sample['folder_scan'],\n",
    "                        'folder_scan': sample['folder_scan'],\n",
    "                        'CDRTOT': sample['CDRTOT'],\n",
    "                        'dataset_type': 'aug',\n",
    "                        'ternary_label': sample['ternary_label'],\n",
    "                        'label': sample['label'],    \n",
    "                        'set': set,                                 \n",
    "                        'T1w': t1w_os_path, \n",
    "                        'T2w': t2w_os_path,\n",
    "                        'aug': 0})\n",
    "        created_folders=created_folders+1\n",
    "        clear_output(wait=False) \n",
    "    print(f\"Operation completed! {created_folders} folders created, {folders_not_added} discarted\")\n",
    "    return train_data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(size):\n",
    "    oversampling_transform = Compose([\n",
    "        EnsureChannelFirst(channel_dim='no_channel'),\n",
    "        Orientation(axcodes='RAS'), \n",
    "        Spacing((1.0, 1.0, 1.0), mode='bilinear', align_corners=True, scale_extent=True),\n",
    "        ScaleIntensity(channel_wise=True),\n",
    "        CropForeground(select_fn=(lambda x: x > 0.3), allow_smaller=True),\n",
    "        Resize(spatial_size=size, size_mode='longest', mode='bilinear', align_corners=True),\n",
    "        SpatialPad(spatial_size=size, mode='minimum'),\n",
    "        # apply randrotate, randflip (or both) with p=1.0 \n",
    "        OneOf([\n",
    "            RandRotate(\n",
    "                prob=1.0, \n",
    "                range_x=0.4, # [-23, 23] degrees\n",
    "                range_y=0.4,\n",
    "                range_z=0.4,\n",
    "                padding_mode='zeros',\n",
    "                align_corners=True),\n",
    "            # mirroring\n",
    "            RandAxisFlip(prob=1.0)], log_stats=True), \n",
    "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensity(factors=0.1, prob=1.0),\n",
    "        RandShiftIntensity(offsets=0.1, prob=1.0)])\n",
    "\n",
    "    train_transform = Compose([\n",
    "        EnsureChannelFirst(channel_dim='no_channel'),\n",
    "        Orientation(axcodes='RAS'), \n",
    "        Spacing((1.0, 1.0, 1.0), mode='bilinear', align_corners=True, scale_extent=True),\n",
    "        ScaleIntensity(channel_wise=True),\n",
    "        CropForeground(select_fn=(lambda x: x > 0.3), allow_smaller=True),\n",
    "        Resize(spatial_size=size, size_mode='longest', mode='bilinear', align_corners=True),\n",
    "        SpatialPad(spatial_size=size, mode='minimum'),\n",
    "        # apply randrotate, randflip (or both) with p=1.0 \n",
    "        RandRotate(\n",
    "            prob=0.2, \n",
    "            range_x=0.4, # [-23, 23] degrees\n",
    "            range_y=0.4,\n",
    "            range_z=0.4,\n",
    "            padding_mode='zeros',\n",
    "            align_corners=True),\n",
    "            # mirroring\n",
    "        RandAxisFlip(prob=0.2), \n",
    "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensity(factors=0.1, prob=1.0),\n",
    "        RandShiftIntensity(offsets=0.1, prob=1.0)])\n",
    "    \n",
    "    eval_transform = Compose([\n",
    "        EnsureChannelFirst(channel_dim='no_channel'),\n",
    "        Orientation(axcodes='RAS'), \n",
    "        Spacing((1.0, 1.0, 1.0), mode='bilinear', align_corners=True, scale_extent=True),\n",
    "        ScaleIntensity(channel_wise=True),\n",
    "        CropForeground(select_fn=(lambda x: x > 0.3), allow_smaller=True),\n",
    "        Resize(spatial_size=size, size_mode='longest', mode='bilinear', align_corners=True),\n",
    "        SpatialPad(spatial_size=size, mode='minimum'),\n",
    "        NormalizeIntensity(nonzero=True, channel_wise=True),\n",
    "        RandScaleIntensity(factors=0.1, prob=1.0),\n",
    "        RandShiftIntensity(offsets=0.1, prob=1.0)])\n",
    "\n",
    "    return oversampling_transform, train_transform, eval_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample_func, train_transform, eval_transform = get_transforms(128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noversampled_dict = oversample_scans(\\n        df=train_df,\\n        transformation_function=oversample_func,\\n        output_dir=output_dir_path,\\n        class_ratios=class_ratio)\\n\\noversampled_df = pd.DataFrame(oversampled_dict)\\npath_os = 'C:/Users/Vito/Desktop/Final Dataset/oversampled_df.csv'\\noversampled_df.to_csv(path_os, index=False)\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampling\n",
    "\n",
    "output_dir_path = 'C:/Users/Vito/Desktop/Final Dataset/train_eval'\n",
    "train_df = final_df[final_df['set'] == 'train+val']\n",
    "class_counts = train_df['label'].value_counts().to_dict()\n",
    "max_desired_labels = max(class_counts.values())\n",
    "class_ratio = {class_label: max_desired_labels  for class_label, count in class_counts.items()}\n",
    "\n",
    "\"\"\"\n",
    "NOTE: uncomment to perform oversampling\n",
    "oversampled_dict = oversample_scans(\n",
    "        df=train_df,\n",
    "        transformation_function=oversample_func,\n",
    "        output_dir=output_dir_path,\n",
    "        class_ratios=class_ratio)\n",
    "\n",
    "oversampled_df = pd.DataFrame(oversampled_dict)\n",
    "path_os = 'C:/Users/Vito/Desktop/Final Dataset/oversampled_df.csv'\n",
    "oversampled_df.to_csv(path_os, index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AD       267\n",
       "CN       267\n",
       "cMCI     267\n",
       "ncMCI    267\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oversampled_df = pd.read_csv('C:/Users/Vito/Desktop/Final Dataset/oversampled_df.csv')\n",
    "train_eval_set_df = pd.concat([train_df, oversampled_df])\n",
    "train_eval_set_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "AD       262\n",
       "CN       240\n",
       "cMCI      51\n",
       "ncMCI    148\n",
       "Name: OASISID, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique patients for this set\n",
    "train_eval_set_df.groupby('label')['OASISID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val set:\n",
      " ncMCI    77\n",
      "cMCI     63\n",
      "CN       49\n",
      "AD       46\n",
      "Name: label, dtype: int64\n",
      "\n",
      " Training set:\n",
      " AD       221\n",
      "CN       218\n",
      "cMCI     204\n",
      "ncMCI    190\n",
      "Name: label, dtype: int64\n",
      "\n",
      " Is the same patient in both sets?: False\n"
     ]
    }
   ],
   "source": [
    "# Split traning and evaluation set\n",
    "def split_train_val(df, verbose):\n",
    "\n",
    "    val_labels_ratio = 40 # how many samples for each label the test set must contain (267*0.15)\n",
    "    random.seed(32)\n",
    "    subjects = df['OASISID'].unique().tolist()\n",
    "    random.shuffle(subjects)\n",
    "    eval_patients=[]\n",
    "\n",
    "    #cMCI is a particular case in which the patients are few since it has been oversampled. So less patients have been taken.\n",
    "    for label in df['label'].unique():     \n",
    "        if label != 'cMCI':\n",
    "            class_samples = df[df['label'] == label]\n",
    "            unique_class_subjects = class_samples['OASISID'].unique()\n",
    "            selected_val_subjects = random.sample(list(unique_class_subjects), val_labels_ratio)\n",
    "            eval_patients.extend(selected_val_subjects)\n",
    "        elif label == 'cMCI':    \n",
    "            class_samples = df[df['label'] == label]\n",
    "            unique_class_subjects = class_samples['OASISID'].unique()\n",
    "            selected_val_subjects = random.sample(list(unique_class_subjects), 10)\n",
    "            eval_patients.extend(selected_val_subjects)\n",
    "\n",
    "    train_subj = df['OASISID'].unique()\n",
    "    train_subj = train_subj[~pd.Series(train_subj).isin(eval_patients)]\n",
    "\n",
    "    X_eval = df[df['OASISID'].isin(eval_patients)]\n",
    "    X_training = df[df['OASISID'].isin(train_subj) & \n",
    "                            (~df['OASISID'].isin(X_eval['OASISID']))]\n",
    "\n",
    "    X_eval = X_eval.reset_index(drop=True)\n",
    "    X_training = X_training.reset_index(drop=True)\n",
    "    if verbose==True:\n",
    "        print('Val set:\\n', X_eval['label'].value_counts())\n",
    "        print('\\n Training set:\\n', X_training['label'].value_counts())\n",
    "        print('\\n Is the same patient in both sets?:', check_duplicates(X_training, X_eval))\n",
    "\n",
    "    return X_training, X_eval\n",
    "\n",
    "train_set_bal, val_set_bal = split_train_val(train_eval_set_df, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original label distribution:\n",
      "AD       221\n",
      "CN       218\n",
      "cMCI     204\n",
      "ncMCI    190\n",
      "Name: label, dtype: int64\n",
      "\n",
      "Resampled label distribution:\n",
      "AD       190\n",
      "CN       190\n",
      "cMCI     190\n",
      "ncMCI    190\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_set_bal['set'] = 'train'\n",
    "features_tr = ['OASISID','OASIS_session_label','folder_scan','CDRTOT','dataset_type','ternary_label','set','T1w','T2w','aug']\n",
    "train_set_bal_os = undersample_final_dataset(train_set_bal,features_tr, verbose=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_bal['set'] = 'val'\n",
    "test_set_final = final_df[final_df['set'] == 'test']\n",
    "\n",
    "final_set_df = pd.concat([train_set_bal_os, val_set_bal, test_set_final])\n",
    "final_set_df.to_csv('C:/Users/Vito/Desktop/Final Dataset/train_eval_test_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_filtered  = train_set_bal[train_set_bal['dataset_type'].isin(['o3', 'o4'])]\n",
    "train_set_filtered = train_set_filtered.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions used to move all the MRI scan files in a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation completed! 606 folders created, 0 discarted\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "train_eval_dir = 'C:/Users/Vito/Desktop/Final Dataset/train_eval'\n",
    "test_dir = 'C:/Users/Vito/Desktop/Final Dataset/test_set'\n",
    "\n",
    "train_set_dict = train_eval_scans_transformation(\n",
    "        train_set_filtered,\n",
    "        train_transform,\n",
    "        train_eval_dir,\n",
    "        'train')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "dict1=pd.DataFrame(train_set_dict)\n",
    "dict2=pd.DataFrame(val_set_dict)\n",
    "df_concat = pd.concat([dict1, dict2], axis=0)\n",
    "df_concat.to_csv('C:/Users/Vito/Desktop/Final Dataset/dict_train_eval.csv', index=False)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation completed! 155 folders created, 0 discarted\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "val_set_filtered  = val_set_bal[val_set_bal['dataset_type'].isin(['o3', 'o4'])]\n",
    "val_set_filtered = val_set_filtered.reset_index(drop=True)\n",
    "\n",
    "val_set_dict = train_eval_scans_transformation(\n",
    "        val_set_filtered,\n",
    "        eval_transform,\n",
    "        train_eval_dir,\n",
    "        'val')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation completed! 238 folders created, 0 discarted\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "test_dir = 'C:/Users/Vito/Desktop/Final Dataset/test_set'\n",
    "test_set_final = test_set_final.reset_index(drop=True)\n",
    "\n",
    "test_set_dict = train_eval_scans_transformation(\n",
    "        test_set_final,\n",
    "        eval_transform,\n",
    "        test_dir,\n",
    "        'test')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "new_data = pd.read_csv('c:/Users/Vito/Desktop/Final Dataset/metadata.csv')\n",
    "pattern1 = r'd(\\d{4})_(\\d{1,2})'\n",
    "pattern2 = r'd(\\d+)'\n",
    "\n",
    "def modify_path(row, path_type):\n",
    "    base_train_eval = '/kaggle/input/oasis-final/Final Dataset/Final Dataset/train_val_set'\n",
    "    base_test = '/kaggle/input/oasis-final/Final Dataset/Final Dataset/test_set'\n",
    "\n",
    "    d = None\n",
    "    duplicates = None\n",
    "\n",
    "    matches1 = re.findall(pattern1, row['folder_scan'])\n",
    "    matches2 = re.search(pattern2, row['folder_scan']).group(1)\n",
    "\n",
    "\n",
    "    if matches1:\n",
    "        for match in matches1:\n",
    "            d = match[0] \n",
    "            duplicates = match[1] \n",
    "    elif matches2:\n",
    "            d = matches2\n",
    "\n",
    "    if row['set'] in ['train', 'val']:\n",
    "\n",
    "        if duplicates != None:\n",
    "            string=f\"{row['OASISID']}_d{d}_{duplicates}_{path_type}.nii\"\n",
    "        else:\n",
    "            string=f\"{row['OASISID']}_d{d}_{path_type}.nii\"\n",
    "\n",
    "        return f\"{base_train_eval}/{row['folder_scan']}/{string}\"\n",
    "    \n",
    "    elif row['set'] == 'test':\n",
    "        string=f\"{row['OASISID']}_d{d}_{path_type}.nii\"\n",
    "        return f\"{base_test}/{row['folder_scan']}/{string}\"\n",
    "\n",
    "new_data['T1w_path'] = new_data.apply(lambda row: modify_path(row, 'T1w'), axis=1)\n",
    "new_data['T2w_path'] = new_data.apply(lambda row: modify_path(row, 'T2w'), axis=1)\n",
    "new_data.drop(columns=['T1w', 'T2w'], inplace=True)\n",
    "new_data.to_csv('c:/Users/Vito/Desktop/Final Dataset/metadata_updated.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
